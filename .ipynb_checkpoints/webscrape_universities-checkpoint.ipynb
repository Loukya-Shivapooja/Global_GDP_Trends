{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb85380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial imports\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cccfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for closing pop ups\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a4fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.4icu.org/reviews/index0001.htm', 'https://www.4icu.org/reviews/index2.htm', 'https://www.4icu.org/reviews/index3.htm', 'https://www.4icu.org/reviews/index4.htm', 'https://www.4icu.org/reviews/index5.htm', 'https://www.4icu.org/reviews/index6.htm', 'https://www.4icu.org/reviews/index7.htm', 'https://www.4icu.org/reviews/index8.htm', 'https://www.4icu.org/reviews/index9.htm', 'https://www.4icu.org/reviews/index10.htm', 'https://www.4icu.org/reviews/index11.htm', 'https://www.4icu.org/reviews/index12.htm', 'https://www.4icu.org/reviews/index13.htm', 'https://www.4icu.org/reviews/index14.htm', 'https://www.4icu.org/reviews/index15.htm', 'https://www.4icu.org/reviews/index16.htm', 'https://www.4icu.org/reviews/index17.htm', 'https://www.4icu.org/reviews/index18.htm', 'https://www.4icu.org/reviews/index19.htm', 'https://www.4icu.org/reviews/index20.htm', 'https://www.4icu.org/reviews/index21.htm', 'https://www.4icu.org/reviews/index22.htm', 'https://www.4icu.org/reviews/index23.htm', 'https://www.4icu.org/reviews/index24.htm', 'https://www.4icu.org/reviews/index25.htm', 'https://www.4icu.org/reviews/index26.htm', 'https://www.4icu.org/reviews/index27.htm']\n"
     ]
    }
   ],
   "source": [
    "#ran into pop ups when automated browser clicks \"next\". \n",
    "# working around problem by opening and closing a new browser for each page of the website.\n",
    "\n",
    "\n",
    "# create a list of urls to visit\n",
    "urls = []\n",
    "\n",
    "# add url for universities that start with 0-9 to list of urls\n",
    "url = (\"https://www.4icu.org/reviews/index0001.htm\")\n",
    "urls.append(url)\n",
    "# print(urls)\n",
    "\n",
    "\n",
    "# add urls for universities that start with A-Z to list of urls\n",
    "#convert int to str found (https://stackoverflow.com/questions/52499991/how-to-append-a-integer-iteration-into-a-string-in-python)\n",
    "# for url in urls:\n",
    "for i in range(2, 28):       \n",
    "    url = 'https://www.4icu.org/reviews/index'+ str(i) +'.htm'\n",
    "    urls.append(url)\n",
    "    \n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8753ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create loop to open new browser, visit each url in the urls list, extract the data, and close the browser\n",
    "\n",
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "\n",
    "#create an empty list for the table data\n",
    "row_data = []\n",
    "\n",
    "for i in urls:\n",
    "    \n",
    "    # set up browser\n",
    "    browser = Browser('chrome', **executable_path, headless=False) \n",
    "               \n",
    "    # Visit UniRank website\n",
    "    url = i\n",
    "    browser.visit(url)\n",
    "    browser.is_element_present_by_css('div.list_text', wait_time=1)\n",
    "\n",
    "    # parse the html\n",
    "    html = browser.html\n",
    "    html_soup = soup(html, 'html.parser')\n",
    "\n",
    "    #isolate the table\n",
    "    universities_table = html_soup.find('table', class_='table table-hover text-left')\n",
    "\n",
    "    #loop through rows, collect data, append data to list, close browser\n",
    "    for i in range(len(urls)):\n",
    "        for row in universities_table.find_all('tr'):\n",
    "            col = row.find_all('td')\n",
    "            col = [ele.text.strip()for ele in col]\n",
    "            row_data.append(col)\n",
    "            \n",
    "    # close browser          \n",
    "    browser.quit()\n",
    "        \n",
    "# print(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045ab906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University Name</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3iL École d'ingénieurs</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           University Name Country\n",
       "0                     None    None\n",
       "1   3iL École d'ingénieurs      fr\n",
       "2                     None    None\n",
       "3   3iL École d'ingénieurs      fr\n",
       "4                     None    None\n",
       "5   3iL École d'ingénieurs      fr\n",
       "6                     None    None\n",
       "7   3iL École d'ingénieurs      fr\n",
       "8                     None    None\n",
       "9   3iL École d'ingénieurs      fr\n",
       "10                    None    None\n",
       "11  3iL École d'ingénieurs      fr\n",
       "12                    None    None\n",
       "13  3iL École d'ingénieurs      fr\n",
       "14                    None    None\n",
       "15  3iL École d'ingénieurs      fr\n",
       "16                    None    None\n",
       "17  3iL École d'ingénieurs      fr\n",
       "18                    None    None\n",
       "19  3iL École d'ingénieurs      fr"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "university_df = pd.DataFrame(row_data, columns=[\"University Name\", \"Country\"])\n",
    "university_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e41db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# university_df.to_csv('C:/Users/sarah/OneDrive/Desktop/Global_GDP_Trends/webscraped_university_names.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb74d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit UniRank website\n",
    "# url = 'https://www.4icu.org/reviews/index2.htm'\n",
    "# browser.visit(url)\n",
    "# browser.is_element_present_by_css('div.list_text', wait_time=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f54319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_soup = soup(html, 'html.parser')\n",
    "# # html_soup\n",
    "# # browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb78fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #isolate the table\n",
    "# universities_table = html_soup.find('table', class_='table table-hover text-left')\n",
    "# # print(table)\n",
    "\n",
    "# #create an empty list for the table data\n",
    "# row_data = []\n",
    "\n",
    "# #loop through rows, collect data, append data to list, close browser\n",
    "# for i in range(1):\n",
    "#     for row in universities_table.find_all('tr'):\n",
    "#         col = row.find_all('td')\n",
    "#         col = [ele.text.strip()for ele in col]\n",
    "#         row_data.append(col)\n",
    "# browser.quit()\n",
    "        \n",
    "\n",
    "# print(row_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bff5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visit UniRank website\n",
    "# url = 'https://www.4icu.org/reviews/index2.htm'\n",
    "# browser.visit(url)\n",
    "# browser.is_element_present_by_css('div.list_text', wait_time=2)\n",
    "\n",
    "# # Set up Splinter\n",
    "# executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "\n",
    "# # set up browser\n",
    "# browser = Browser('chrome', **executable_path, headless=False) \n",
    "\n",
    "#     driver.find_element_by_xpath('//div[contains(@class,\"abgac\") and @aria-descri\n",
    "\n",
    "#     #handle popup\n",
    "#     html = browser.html\n",
    "#     html_soup = soup(html, 'html.parser')\n",
    "#     html_soup\n",
    "#     browser.links.find_by_partial_text('Close').click()\n",
    "\n",
    "\n",
    "#  #wait for pop up and close\n",
    "#     wait = WebDriverWait(executable_path, 20)\n",
    "#     wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[@title='Close']\"))).click()\n",
    "\n",
    "\n",
    "\n",
    "# for x in range(1, 1):\n",
    "#    html = browser.html\n",
    "#    college_name_soup = soup(html, 'html.parser')\n",
    "#    college_name = college_name_soup.find_all('table', class_='table table-hover text-left')\n",
    "#    for name in college_name:\n",
    "#       print('page:', x, '----------')\n",
    "#       print(college_name.text)\n",
    "#    browser.links.find_by_partial_text('Next').click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_html()[0]\n",
    "# df.columns=['University', 'Country']\n",
    "# df.set_index('University', inplace=True)\n",
    "# df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #get headers\n",
    "# headers = []\n",
    "# for i in table.find_all('th'):\n",
    "#     title = i.text\n",
    "#     headers.append(title)\n",
    "# # print(headers)\n",
    "\n",
    "# #create dictionary for data\n",
    "# college_data = {}\n",
    "\n",
    "# #create a dataframe for universities\n",
    "# df = pd.DataFrame(columns = headers)\n",
    "\n",
    "# #loop through each page for each letter of the alphebet\n",
    "\n",
    "# #fetch data from table\n",
    "# for row in table.find_all('tr')[1:]:\n",
    "#     data = row.find_all('td')\n",
    "#     row_data = [td.text.strip()for td in data]\n",
    "# college_data.append(row_data)\n",
    "# print(college_data)    \n",
    "\n",
    "\n",
    "    \n",
    "#     length = len(df)\n",
    "#   df.loc[length] = row_data    \n",
    "# df\n",
    "\n",
    "# for x in range(1, 1):\n",
    "#    html = browser.html\n",
    "#    college_name_soup = soup(html, 'html.parser')\n",
    "#    college_name = college_name_soup.find_all('table', class_='table table-hover text-left')\n",
    "#    for name in college_name:\n",
    "#       print('page:', x, '----------')\n",
    "#       print(college_name.text)\n",
    "#    browser.links.find_by_partial_text('Next').click()\n",
    "\n",
    "# for x in range(1,1):\n",
    "#    html = browser.html\n",
    "#    quote_soup = soup(html, 'html.parser')\n",
    "#    quotes = quote_soup.find_all('span', class_='text')\n",
    "#    for quote in quotes:\n",
    "#       print('page:', x, '----------')\n",
    "#       print(quote.text)\n",
    "#    browser.links.find_by_partial_text('Next').click()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
